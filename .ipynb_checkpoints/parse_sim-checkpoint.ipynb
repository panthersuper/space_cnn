{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from numpy import array\n",
    "\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "\n",
    "SOURCE_URL = 'http://pwz.mit.edu/data/'\n",
    "WORK_DIRECTORY = \"/img-data\"\n",
    "\n",
    "def maybe_download(filename):\n",
    "    \"\"\"A helper to download the data files if not present.\"\"\"\n",
    "    if not os.path.exists(WORK_DIRECTORY):\n",
    "        os.mkdir(WORK_DIRECTORY)\n",
    "    filepath = os.path.join(WORK_DIRECTORY, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        filepath, _ = urlretrieve(SOURCE_URL + filename, filepath)\n",
    "        statinfo = os.stat(filepath)\n",
    "        print('Succesfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "    else:\n",
    "        print('Already downloaded', filename)\n",
    "    return filepath  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Already downloaded', '0-interial.txt')\n",
      "('Already downloaded', '1-exterial.txt')\n",
      "('Already downloaded', '2-outmost.txt')\n",
      "40\n",
      "60\n",
      "30\n",
      "120 120\n",
      "[[-0.00533333 -0.00533333  0.01066667]\n",
      " [-0.00536478 -0.00536478  0.01072956]\n",
      " [-0.00546101 -0.00546101  0.01092202]\n",
      " ..., \n",
      " [-0.01666667 -0.01666666  0.03333333]\n",
      " [-0.01666667 -0.01666666  0.03333333]\n",
      " [-0.01666667 -0.01666666  0.03333333]]\n",
      "[-0.01666667 -0.01666666  0.03333333]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "interial_data = maybe_download('0-interial.txt')\n",
    "exterial_data = maybe_download('1-exterial.txt')\n",
    "outmost_data = maybe_download('2-outmost.txt')\n",
    "\n",
    "with open(interial_data, 'r') as f0:\n",
    "    with open(exterial_data, 'r') as f1:\n",
    "        with open(outmost_data, 'r') as f2:\n",
    "            int_d = json.load(f0)\n",
    "            ext_d = json.load(f1)\n",
    "            out_d = json.load(f2)\n",
    "            \n",
    "            print len(d)\n",
    "            print len(d[0])\n",
    "            print len(d[0][0])\n",
    "            \n",
    "            train_data = []\n",
    "            train_label = []\n",
    "            \n",
    "            for img in int_d:\n",
    "                temp = []\n",
    "                for row in img:\n",
    "                    for i in row:\n",
    "                        temp.append(i)\n",
    "                train_data.append(temp)\n",
    "                train_label.append([1.0,0,0])\n",
    "            for img in ext_d:\n",
    "                temp = []\n",
    "                for row in img:\n",
    "                    for i in row:\n",
    "                        temp.append(i)\n",
    "                train_data.append(temp)\n",
    "                train_label.append([0,1.0,0])\n",
    "            for img in out_d:\n",
    "                temp = []\n",
    "                for row in img:\n",
    "                    for i in row:\n",
    "                        temp.append(i)\n",
    "                train_data.append(temp)\n",
    "                train_label.append([0,0,1.0])\n",
    "            \n",
    "            print len(train_data),len(train_label)\n",
    "            \n",
    "            x = tf.placeholder(tf.float32,[None,1800])\n",
    "            W = tf.Variable(tf.zeros([1800, 3])) # now have 3 labels, each pixel to each label have a weight\n",
    "            b = tf.Variable(tf.zeros([3])) #each label have one bias\n",
    "            y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "            y_ = tf.placeholder(tf.float32, [None, 3]) # the placeholder for the right labels\n",
    "            \n",
    "            cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "            train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)\n",
    "            \n",
    "            init = tf.initialize_all_variables()\n",
    "            sess = tf.Session()\n",
    "            sess.run(init)                \n",
    "            \n",
    "            \n",
    "            def normalize(lst):\n",
    "                return [i/5000 for i in lst]\n",
    "                \n",
    "                \n",
    "            #print normalize(train_data[0])\n",
    "            train_data = [normalize(i) for i in train_data]\n",
    "\n",
    "            for i in range(12):\n",
    "                batch_xs, batch_ys = array(train_data[10*i:10*i+10]), array(train_label[10*i:10*i+10])\n",
    "                sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "            print sess.run(W)\n",
    "            print sess.run(b)\n",
    "            correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "            #print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
