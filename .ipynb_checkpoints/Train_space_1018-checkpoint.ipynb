{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from numpy import array\n",
    "import random\n",
    "random.seed( 3 )\n",
    "\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "\n",
    "SOURCE_URL = 'http://pwz.mit.edu/data/train1018/'\n",
    "WORK_DIRECTORY = \"/train1018\"\n",
    "\n",
    "def maybe_download(filename):\n",
    "    \"\"\"A helper to download the data files if not present.\"\"\"\n",
    "    if not os.path.exists(WORK_DIRECTORY):\n",
    "        os.mkdir(WORK_DIRECTORY)\n",
    "    filepath = os.path.join(WORK_DIRECTORY, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        filepath, _ = urlretrieve(SOURCE_URL + filename, filepath)\n",
    "        statinfo = os.stat(filepath)\n",
    "        print('Succesfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "    else:\n",
    "        print('Already downloaded', filename)\n",
    "    return filepath  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Succesfully downloaded', '0.txt', 1183939, 'bytes.')\n",
      "('Succesfully downloaded', '1.txt', 1229657, 'bytes.')\n",
      "('Succesfully downloaded', '2.txt', 1372953, 'bytes.')\n",
      "('Succesfully downloaded', '3.txt', 1275982, 'bytes.')\n",
      "('Succesfully downloaded', '4.txt', 1393561, 'bytes.')\n",
      "('Succesfully downloaded', '5.txt', 1306952, 'bytes.')\n",
      "('Succesfully downloaded', '6.txt', 1396880, 'bytes.')\n",
      "('Succesfully downloaded', '7.txt', 1325497, 'bytes.')\n",
      "('Succesfully downloaded', '8.txt', 1403196, 'bytes.')\n",
      "('Succesfully downloaded', '9.txt', 1351323, 'bytes.')\n",
      "('Succesfully downloaded', '10.txt', 1409905, 'bytes.')\n"
     ]
    }
   ],
   "source": [
    "data0 = maybe_download('0.txt')\n",
    "data1 = maybe_download('1.txt')\n",
    "data2 = maybe_download('2.txt')\n",
    "data3 = maybe_download('3.txt')\n",
    "data4 = maybe_download('4.txt')\n",
    "data5 = maybe_download('5.txt')\n",
    "data6 = maybe_download('6.txt')\n",
    "data7 = maybe_download('7.txt')\n",
    "data8 = maybe_download('8.txt')\n",
    "data9 = maybe_download('9.txt')\n",
    "data10 = maybe_download('10.txt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(data0, 'r') as f0,open(data1, 'r') as f1,open(data2, 'r') as f2,open(data3, 'r') as f3,open(data4, 'r') as f4,open(data5, 'r') as f5,open(data6, 'r') as f6,open(data7, 'r') as f7,open(data8, 'r') as f8,open(data9, 'r') as f9,open(data10, 'r') as f10:\n",
    "    dd = []\n",
    "    \n",
    "    dd.append(json.load(f0))\n",
    "    dd.append(json.load(f1))\n",
    "    dd.append(json.load(f2))\n",
    "    dd.append(json.load(f3))\n",
    "    dd.append(json.load(f4))\n",
    "    dd.append(json.load(f5))\n",
    "    dd.append(json.load(f6))\n",
    "    dd.append(json.load(f7))\n",
    "    dd.append(json.load(f8))\n",
    "    dd.append(json.load(f9))\n",
    "    dd.append(json.load(f10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.32078692  0.32267848  0.32846628 ...,  2.          2.          2.        ]\n",
      " [ 0.32078692  0.32267848  0.32846628 ...,  2.          2.          2.        ]\n",
      " [ 0.32078692  0.32267848  0.32846628 ...,  2.          2.          2.        ]\n",
      " ..., \n",
      " [ 0.32078692  0.32267848  0.32846628 ...,  0.28670296  0.28165105  0.28      ]\n",
      " [ 0.32078692  0.32267848  0.32846628 ...,  0.28670296  0.28165105  0.28      ]\n",
      " [ 0.32078692  0.32267848  0.32846628 ...,  0.28670296  0.28165105  0.28      ]]\n",
      "[[1 0 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " [0 0 0 ..., 0 0 1]]\n",
      "440\n"
     ]
    }
   ],
   "source": [
    "    train_data = []\n",
    "    train_label = []\n",
    "    test_data = []\n",
    "    \n",
    "    \n",
    "    def combineSet(datamat,labelmat,data0,label):\n",
    "        for img in data0:\n",
    "            temp = []\n",
    "            for row in img:\n",
    "                for i in row:\n",
    "                    temp.append(i)\n",
    "            datamat.append(temp)\n",
    "            labelmat.append(label)\n",
    "    \n",
    "    def labelcreator(index,total):\n",
    "        out = [0 for i in range(total)]\n",
    "        out[index]=1\n",
    "        return out\n",
    "            \n",
    "    for i in range(11):\n",
    "        combineSet(train_data,train_label,dd[i],labelcreator(i,11))\n",
    "\n",
    "    def normalize(lst):\n",
    "        return [i/5000 for i in lst]\n",
    "\n",
    "\n",
    "    #print normalize(train_data[0])\n",
    "    train_data = [normalize(i) for i in train_data]\n",
    "    test_data = [normalize(i) for i in test_data]\n",
    "\n",
    "    \n",
    "    print array(train_data)\n",
    "    print array(train_label)\n",
    "    print len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    setsize = 20\n",
    "    setAll = 440\n",
    "    \n",
    "    def subset(lst,index,num):\n",
    "        if index+num<len(lst):\n",
    "            return lst[index:index+num]\n",
    "        else:\n",
    "            lst0 = lst[index:]\n",
    "            lst1 = lst[:(num-(len(lst)-index))]\n",
    "            lst0.extend(lst1)\n",
    "\n",
    "    print len(subset(train_data,110,setsize))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    x = tf.placeholder(tf.float32,[None,1800])\n",
    "    W = tf.Variable(tf.zeros([1800, 11])) # now have 3 labels, each pixel to each label have a weight\n",
    "    b = tf.Variable(tf.zeros([11])) #each label have one bias\n",
    "    y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "    y_ = tf.placeholder(tf.float32, [None, 11]) # the placeholder for the right labels\n",
    "\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.0001).minimize(cross_entropy)\n",
    "\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    sess.run(init)                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(50000):\n",
    "        myindex =  int(random.random()*setAll)\n",
    "        if i%100 == 0:\n",
    "            print i\n",
    "        batch_xs, batch_ys = array(subset(train_data,myindex,setsize)), array(subset(train_label,myindex,setsize))\n",
    "        sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    \n",
    "    #print array(train_data[0]),array(test_data[0])\n",
    "    print sess.run(W)\n",
    "    print sess.run(b)\n",
    "    #correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    #accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    sys_prediction = y\n",
    "    #print sess.run(sys_prediction, feed_dict={x: array(test_data)})\n",
    "    \n",
    "    #print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
