{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Already downloaded', '0.txt')\n",
      "('Already downloaded', '1.txt')\n",
      "('Already downloaded', '2.txt')\n",
      "('Already downloaded', '3.txt')\n",
      "('Already downloaded', '4.txt')\n",
      "('Already downloaded', '5.txt')\n",
      "('Already downloaded', '6.txt')\n",
      "('Already downloaded', '7.txt')\n",
      "('Already downloaded', '8.txt')\n",
      "('Already downloaded', '9.txt')\n",
      "('Already downloaded', '10.txt')\n",
      "('Already downloaded', '11.txt')\n",
      "('Already downloaded', '12.txt')\n",
      "('Already downloaded', '13.txt')\n",
      "('Already downloaded', '14.txt')\n",
      "('Already downloaded', 'test2.txt')\n",
      "182 60 30\n",
      "[[ 0.32        0.32188691  0.32766052 ...,  2.          2.          2.        ]\n",
      " [ 0.32        0.32188691  0.32766052 ...,  2.          2.          2.        ]\n",
      " [ 0.32        0.32188691  0.32766052 ...,  2.          2.          2.        ]\n",
      " ..., \n",
      " [ 0.32        0.32188691  0.32766052 ...,  2.          2.          2.        ]\n",
      " [ 0.32        0.32188691  0.32766052 ...,  2.          2.          2.        ]\n",
      " [ 0.32        0.32188691  0.32766052 ...,  2.          2.          2.        ]]\n",
      "1800\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from numpy import array\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed( 3 )\n",
    "\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "\n",
    "\n",
    "\n",
    "SOURCE_URL = 'http://pwz.mit.edu/data/train1018/'\n",
    "\n",
    "WORK_DIRECTORY = \"/train1018\"\n",
    "\n",
    "\n",
    "\n",
    "def maybe_download(filename):\n",
    "\n",
    "    \"\"\"A helper to download the data files if not present.\"\"\"\n",
    "\n",
    "    if not os.path.exists(WORK_DIRECTORY):\n",
    "\n",
    "        os.mkdir(WORK_DIRECTORY)\n",
    "\n",
    "    filepath = os.path.join(WORK_DIRECTORY, filename)\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "\n",
    "        filepath, _ = urlretrieve(SOURCE_URL + filename, filepath)\n",
    "\n",
    "        statinfo = os.stat(filepath)\n",
    "\n",
    "        print('Succesfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "\n",
    "    else:\n",
    "\n",
    "        print('Already downloaded', filename)\n",
    "\n",
    "    return filepath  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data0 = maybe_download('0.txt')\n",
    "\n",
    "data1 = maybe_download('1.txt')\n",
    "\n",
    "data2 = maybe_download('2.txt')\n",
    "\n",
    "data3 = maybe_download('3.txt')\n",
    "\n",
    "data4 = maybe_download('4.txt')\n",
    "\n",
    "data5 = maybe_download('5.txt')\n",
    "\n",
    "data6 = maybe_download('6.txt')\n",
    "\n",
    "data7 = maybe_download('7.txt')\n",
    "\n",
    "data8 = maybe_download('8.txt')\n",
    "\n",
    "data9 = maybe_download('9.txt')\n",
    "\n",
    "data10 = maybe_download('10.txt')\n",
    "\n",
    "data11 = maybe_download('11.txt')\n",
    "\n",
    "data12 = maybe_download('12.txt')\n",
    "\n",
    "data13 = maybe_download('13.txt')\n",
    "\n",
    "data14 = maybe_download('14.txt')\n",
    "\n",
    "\n",
    "\n",
    "test = maybe_download('test2.txt')\n",
    "\n",
    "\n",
    "\n",
    "with open(data0, 'r') as f0,open(data1, 'r') as f1,open(data2, 'r') as f2,open(data3, 'r') as f3,open(data4, 'r') as f4,open(data5, 'r') as f5,open(data6, 'r') as f6,open(data7, 'r') as f7,open(data8, 'r') as f8,open(data9, 'r') as f9,open(data10, 'r') as f10,open(data11, 'r') as f11,open(data12, 'r') as f12,open(data13, 'r') as f13,open(data14, 'r') as f14,open(test, 'r') as ft:\n",
    "\n",
    "    dd = []\n",
    "\n",
    "    \n",
    "\n",
    "    dd.append(json.load(f0))\n",
    "\n",
    "    dd.append(json.load(f1))\n",
    "\n",
    "    dd.append(json.load(f2))\n",
    "\n",
    "    dd.append(json.load(f3))\n",
    "\n",
    "    dd.append(json.load(f4))\n",
    "\n",
    "    dd.append(json.load(f5))\n",
    "\n",
    "    dd.append(json.load(f6))\n",
    "\n",
    "    dd.append(json.load(f7))\n",
    "\n",
    "    dd.append(json.load(f8))\n",
    "\n",
    "    dd.append(json.load(f9))\n",
    "\n",
    "    dd.append(json.load(f10))\n",
    "\n",
    "    dd.append(json.load(f11))\n",
    "\n",
    "    dd.append(json.load(f12))\n",
    "\n",
    "    dd.append(json.load(f13))\n",
    "\n",
    "    dd.append(json.load(f14))\n",
    "\n",
    "    \n",
    "\n",
    "    test_d = json.load(ft)\n",
    "\n",
    "    \n",
    "\n",
    "    print len(test_d),len(test_d[0]),len(test_d[0][0])\n",
    "\n",
    "    train_data = []\n",
    "\n",
    "    train_label = []\n",
    "\n",
    "    test_data = []\n",
    "\n",
    "\n",
    "\n",
    "    def combineSet(datamat,labelmat,data0,label):\n",
    "\n",
    "        for img in data0:\n",
    "\n",
    "            temp = []\n",
    "\n",
    "            for row in img:\n",
    "\n",
    "                for i in row:\n",
    "\n",
    "                    temp.append(i)\n",
    "\n",
    "            datamat.append(temp)\n",
    "\n",
    "            labelmat.append(label)\n",
    "\n",
    "\n",
    "\n",
    "    def labelcreator(index,total):\n",
    "\n",
    "        out = [0 for i in range(total)]\n",
    "\n",
    "        out[index]=1\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(15):\n",
    "\n",
    "        combineSet(train_data,train_label,dd[i],labelcreator(i,15))\n",
    "\n",
    "\n",
    "\n",
    "    def normalize(lst):\n",
    "\n",
    "        return [i/5000 for i in lst]\n",
    "\n",
    "\n",
    "\n",
    "    for img in test_d:\n",
    "\n",
    "        temp = []\n",
    "\n",
    "        for row in img:\n",
    "\n",
    "            for i in row:\n",
    "\n",
    "                temp.append(i)\n",
    "\n",
    "        test_data.append(temp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #print normalize(train_data[0])\n",
    "\n",
    "    train_data = [normalize(i) for i in train_data]\n",
    "\n",
    "    test_data = [normalize(i) for i in test_data]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #print array(train_data)\n",
    "\n",
    "    print array(test_data)\n",
    "\n",
    "    print len(test_data[0])\n",
    "\n",
    "    #print len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 1800],name = \"x\")\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 15],name = \"y_\")\n",
    "\n",
    "\n",
    "\n",
    "def weight_variable(shape,name):\n",
    "\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "\n",
    "  return tf.Variable(initial,name)\n",
    "\n",
    "\n",
    "\n",
    "def bias_variable(shape,name):\n",
    "\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "\n",
    "  return tf.Variable(initial,name)\n",
    "\n",
    "def conv2d(x, W):\n",
    "\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "\n",
    "#1st conv\n",
    "\n",
    "\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 1, 32],name=\"W_conv1\")\n",
    "\n",
    "b_conv1 = bias_variable([32],name=\"b_conv1\")\n",
    "\n",
    "\n",
    "\n",
    "x_image = tf.reshape(x, [-1,60,30,1])\n",
    "\n",
    "\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#2nd conv\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64],name=\"v3\")\n",
    "\n",
    "b_conv2 = bias_variable([64],name=\"v4\")\n",
    "\n",
    "\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "\n",
    "\n",
    "#Densely Connected Layer\n",
    "\n",
    "W_fc1 = weight_variable([15 * 8 * 64, 1024],name=\"v5\")\n",
    "\n",
    "b_fc1 = bias_variable([1024],name=\"v6\")\n",
    "\n",
    "\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 15*8*64])\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "\n",
    "\n",
    "#Dropout\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32,name = \"keep_prob\")\n",
    "\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "\n",
    "\n",
    "#readout\n",
    "\n",
    "W_fc2 = weight_variable([1024, 15],name=\"v7\")\n",
    "\n",
    "b_fc2 = bias_variable([15],name=\"v8\")\n",
    "\n",
    "\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "[[  1.32879417e-04   2.25414010e-06   1.01246380e-08 ...,   3.59954316e-10\n",
      "    4.86859129e-11   1.62996781e-08]\n",
      " [  3.83797851e-05   3.20959498e-06   5.92517857e-09 ...,   5.45417767e-10\n",
      "    5.62245979e-11   1.23042501e-08]\n",
      " [  1.35123919e-05   1.45050335e-05   4.42931691e-09 ...,   4.25440932e-10\n",
      "    1.99394719e-11   4.42705339e-09]\n",
      " ..., \n",
      " [  6.29831195e-01   3.67214024e-01   6.73076102e-06 ...,   6.66724731e-11\n",
      "    1.79617672e-08   1.54602400e-10]\n",
      " [  3.18274379e-01   6.81322992e-01   1.27270266e-06 ...,   2.43458899e-11\n",
      "    6.47126441e-09   2.78440014e-11]\n",
      " [  1.89288840e-01   8.10646832e-01   4.42230998e-07 ...,   1.17947310e-11\n",
      "    1.96765204e-09   3.60799129e-12]]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "\n",
    "# do some work with the model.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Restore variables from disk.\n",
    "\n",
    "    saver.restore(sess, \"/notebooks/cnnmodel.ckpt\")\n",
    "\n",
    "    print(\"Model restored.\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    myy = tf.nn.softmax(y_conv)\n",
    "\n",
    "    sys_prediction = myy\n",
    "\n",
    "\n",
    "\n",
    "    #print len(test_data),len(test_data[0])\n",
    "\n",
    "    print sess.run(sys_prediction, feed_dict={x: array(test_data), keep_prob: 1.0})\n",
    "\n",
    "\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "    #print sys_prediction.eval(sess,feed_dict={x: array(test_data)})\n",
    "\n",
    "    out = \"[\"\n",
    "\n",
    "\n",
    "\n",
    "    for (x,y), value in np.ndenumerate(sess.run(sys_prediction, feed_dict={x: array(test_data), keep_prob: 1.0})):\n",
    "\n",
    "        if y == 0:\n",
    "\n",
    "            print x\n",
    "\n",
    "            if x != 0:\n",
    "\n",
    "                out +=\"]\"\n",
    "\n",
    "            out += \"[\"\n",
    "\n",
    "\n",
    "\n",
    "        out += str(value)+\",\"\n",
    "\n",
    "\n",
    "\n",
    "    out += \"]]\"\n",
    "\n",
    "\n",
    "\n",
    "    with open(\"test2_result_cnn.txt\", \"w\") as text_file:\n",
    "\n",
    "        text_file.write(out)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
